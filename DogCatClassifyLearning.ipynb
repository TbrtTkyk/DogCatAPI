{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DogCatClassifyLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "画像を、犬か猫かの２択（「分からない」無し）で分類するAIを作りたい！"
      ],
      "metadata": {
        "id": "mIVk9ZmCPn8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 事前準備"
      ],
      "metadata": {
        "id": "CXCMrWd-I_fu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインポート"
      ],
      "metadata": {
        "id": "ALHF4tHYJHg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aWu2sWXI3zZ"
      },
      "outputs": [],
      "source": [
        "!pip install icrawler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "import torch.utils.data\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tqdm, time\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn  # 可視化に関するライブラリです。\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IvzTe2DnJOof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定数の定義"
      ],
      "metadata": {
        "id": "AI9XKht-JQ4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"dog\", \"cat\"]\n",
        "num_classes = len(classes)\n",
        "scraping_max = 200# スクレイピングで集める画像の最大枚数\n",
        "image_size = 64   # 画像サイズ（vgg11：224, 自前NN：64）\n",
        "num_testdata = 25 # テストデータの数\n",
        "BATCH_SIZE = 175  # バッチサイズ\n",
        "EPOCHS = 50       # エポック数\n",
        "NPY_FILE_NAME = \"dog_cat.npy\" # 画像データの保存ファイル名\n",
        "\n",
        "# 使用デバイス\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Q1envyV4JTxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像データのスクレイピング"
      ],
      "metadata": {
        "id": "OTzBUAIzJYfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考サイト：[AI Academy | Deep Learningで犬・猫を分類してみよう](https://aiacademy.jp/texts/show/?id=164)"
      ],
      "metadata": {
        "id": "zYCnf71WNcsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像を集める"
      ],
      "metadata": {
        "id": "-huWUOh_KhoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データ収集\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# 「猫」で画像収集\n",
        "crawler = BingImageCrawler(downloader_threads=4, storage={\"root_dir\": \"cat\"})\n",
        "crawler.crawl(keyword=\"猫\", max_num=scraping_max)\n",
        "\n",
        "# 「犬」で画像収集\n",
        "crawler = BingImageCrawler(downloader_threads=4, storage={\"root_dir\": \"dog\"})\n",
        "crawler.crawl(keyword=\"犬\", max_num=scraping_max)"
      ],
      "metadata": {
        "id": "FNbXtJvFJcYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像をndarrayに変換してファイルに保存する"
      ],
      "metadata": {
        "id": "Y6Qr2N5CKkZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像の一部切り取りプロセス\n",
        "train_process = transforms.Compose([\n",
        "  transforms.Resize(image_size*4//3),\n",
        "  transforms.RandomCrop(image_size),\n",
        "])\n",
        "\n",
        "# 画像データ変換処理\n",
        "X_train = []\n",
        "X_test = []\n",
        "Y_train = []\n",
        "Y_test = []\n",
        "for index, classlabel in enumerate(classes):\n",
        "  # フォルダにある特定の種類の動物の画像ファイルを読み込む\n",
        "  photos_dir = \"./\" + classlabel\n",
        "  files = glob.glob(photos_dir + \"/*.jpg\")\n",
        "  for i, file in enumerate(files[:140]):\n",
        "    # 画像データを１つずつ読み込み、サイズ等の調整\n",
        "    image = Image.open(file)\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    if i < num_testdata:\n",
        "      # テストデータとして保存する\n",
        "      image = image.resize((image_size, image_size))\n",
        "      data = np.asarray(image)\n",
        "      X_test.append(data)\n",
        "      Y_test.append(index)\n",
        "    else:\n",
        "      # 学習用データとして保存する\n",
        "      image2 = image.copy()\n",
        "      width, height = image.size\n",
        "      for i in range(2):\n",
        "        image = train_process(image)\n",
        "\n",
        "        # 角度を少しずつずらしたものをそれぞれ保存する\n",
        "        for angle in range(-20, 20, 10):\n",
        "          img_r = image.rotate(angle)\n",
        "          data = np.asarray(img_r)\n",
        "          X_train.append(data)\n",
        "          Y_train.append(index)\n",
        "          img_trains = img_r.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "          data = np.asarray(img_trains)\n",
        "          X_train.append(data)\n",
        "          Y_train.append(index)\n",
        "\n",
        "# 配列をndarray型に直し、npyファイル（dog_cat.npy）として保存する\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_train = np.array(Y_train)\n",
        "Y_test = np.array(Y_test)\n",
        "xy = (X_train, X_test, Y_train, Y_test)\n",
        "np.save(\"./\" + NPY_FILE_NAME, xy)"
      ],
      "metadata": {
        "id": "dvELLca9KsLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセットの準備"
      ],
      "metadata": {
        "id": "bNdRWDupLspB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NPYファイルを読み込む"
      ],
      "metadata": {
        "id": "Tdff3WuGLx9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数ジェネレータの生成\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "# npyファイルを読み込む\n",
        "def load_data():\n",
        "  X_train, X_test, Y_train, Y_test = np.load(\"./\" + NPY_FILE_NAME, allow_pickle=True)\n",
        "\n",
        "  # 入力データの正規化\n",
        "  X_train = torch.from_numpy(X_train.astype(np.float32) * 2 / 255 - 1)\n",
        "  X_test = torch.from_numpy(X_test.astype(np.float32) * 2 / 255 - 1)\n",
        "  # 出力データをワンホットベクトルに変換\n",
        "  Y_train = torch.from_numpy(Y_train)\n",
        "  Y_test = torch.from_numpy(Y_test)\n",
        "  return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "sample = load_data()"
      ],
      "metadata": {
        "id": "bbTG0AxvL2Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データローダーの準備"
      ],
      "metadata": {
        "id": "dIxAKawyQm1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットの作成\n",
        "train_dataset = torch.utils.data.TensorDataset(sample[0], sample[2])#.to(torch.float32))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(sample[1], sample[3])#.to(torch.float32))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 形状の計算\n",
        "input_shape = (image_size, image_size, 3)\n",
        "output_shape = num_classes"
      ],
      "metadata": {
        "id": "-wP0YupNSIG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像データ例の表示"
      ],
      "metadata": {
        "id": "g9Z9FDSYS9oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータを表示\n",
        "pos = 1\n",
        "index = random.randint(0, sample[1].shape[0] / 2)\n",
        "i = index\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "for img in sample[1][index:index + 30]:\n",
        "    plt.subplot(3, 10, pos)\n",
        "    plt.imshow(img * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[torch.argmax(sample[3][i])])\n",
        "    pos += 1\n",
        "    i += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n_55jlBfTCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用データを表示\n",
        "pos = 1\n",
        "index = random.randint(0, sample[0].shape[0] / 2)\n",
        "i = index\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "for img in sample[0][index:index + 30]:\n",
        "    plt.subplot(3, 10, pos)\n",
        "    plt.imshow(img * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[torch.argmax(sample[2][i])])\n",
        "    pos += 1\n",
        "    i += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qBMG-Sf8TKWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像データを学習"
      ],
      "metadata": {
        "id": "0i6pD4U1TXVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NNモデルを準備"
      ],
      "metadata": {
        "id": "FqR4U2pjUFvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習済モデルから用意する場合（ファインチューニング）\n",
        "(無料版Colabのメモリ制限的に上手く学習するのは厳しかった)"
      ],
      "metadata": {
        "id": "Oi3gljw8ThU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済みの重みを使用\n",
        "use_pretrained = True\n",
        "\n",
        "# vgg11モデルをロード（入力に用いる画像は224×224を使用）\n",
        "model = models.vgg11(pretrained=use_pretrained)\n",
        "\n",
        "# 変更前のモデルを出力\n",
        "print(\"変更前モデル\")\n",
        "print(model)\n",
        "\n",
        "# 最後の層を変更\n",
        "model.classifier[6] = nn.Linear(4096, 2)\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "# 変更後のモデルを出力\n",
        "print(\"変更後モデルの線形層\")\n",
        "print(model.classifier)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "summary(model, (3, image_size, image_size))\n"
      ],
      "metadata": {
        "id": "eQKim6XPTs0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NNモデルを自前で用意する場合"
      ],
      "metadata": {
        "id": "F6uJ9C_FULGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力に用いる画像サイズは64×64を想定\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # 入力のチャネル、出力のチャネル（＝フィルター数）、フィルタのサイズ（3 * 3）\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "        # 64 -> 32 -> 16 -> 8 -> 4\n",
        "        # 128 * 4 * 4 = 2048\n",
        "        self.fc1 = nn.Linear(2048, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "summary(model, (3, image_size, image_size))\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "print('入力のサイズ:', input_shape)\n",
        "print('出力のサイズ:', output_shape)"
      ],
      "metadata": {
        "id": "oUKUE1KIUOCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの学習"
      ],
      "metadata": {
        "id": "4zQ4YKC-Ui6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失と正解率の計算関数\n",
        "def calc_loss_and_accuracy(loader_list):\n",
        "    acc = 0\n",
        "    cnt = 0\n",
        "    loss = 0\n",
        "    for (x, y) in tqdm.tqdm(loader_list, \"evaluating... \", position=0, leave=True):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        x = torch.reshape(x, (-1, 3, image_size, image_size))\n",
        "        y = torch.reshape(y, (-1,))\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss += criterion(pred, y).item()\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "        for o, t in zip(pred, y):\n",
        "            if o == t:\n",
        "                acc += 1\n",
        "            cnt += 1\n",
        "    return loss / len(loader_list), acc / cnt"
      ],
      "metadata": {
        "id": "pD_CZODQUmDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "def train(epochs):\n",
        "    train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
        "    train_loader_list = list(train_loader)\n",
        "    test_loader_list = list(test_loader)\n",
        "    for epoch in range(epochs):\n",
        "        for (x, y) in tqdm.tqdm(train_loader_list, f\"[{epoch + 1}/{epochs}] training... \", position=0, leave=True):\n",
        "            x = torch.reshape(x, (-1, 3, image_size, image_size))\n",
        "            y = torch.reshape(y, (-1,))#2))\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y) * 10\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        #print(pred[:5])\n",
        "\n",
        "        train_loss, train_acc = calc_loss_and_accuracy(train_loader_list)\n",
        "        test_loss, test_acc = calc_loss_and_accuracy(test_loader_list)\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(test_acc)\n",
        "        print(\n",
        "            f'\\n[*] train_Loss = {train_loss} | train_Accuracy = {train_acc} | test_Loss = {test_loss}| test_Accuracy = {test_acc}')\n",
        "    return train_losses, train_accs, test_losses, test_accs\n",
        "\n",
        "st = time.time()\n",
        "train_losses, train_accs, test_losses, test_accs = train(EPOCHS)\n",
        "elapsed_time = time.time() - st\n"
      ],
      "metadata": {
        "id": "HgH6xIpVUmFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習結果の確認"
      ],
      "metadata": {
        "id": "lB3sHDP2ViH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train loss:', train_losses[len(train_losses) - 1])\n",
        "print('Test loss:', test_losses[len(test_losses) - 1])\n",
        "\n",
        "print('Train accuracy:', train_accs[len(train_accs) - 1])\n",
        "print('Test accuracy:', test_accs[len(test_accs) - 1])\n",
        "\n",
        "print('実行時間(秒) : ', elapsed_time)"
      ],
      "metadata": {
        "id": "SDvD4X85VoEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習過程をグラフで表示"
      ],
      "metadata": {
        "id": "sAtkOy_yVrTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_accs)\n",
        "plt.plot(test_accs)\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.plot(test_losses)\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7C52u-x8Vqsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習モデルのテスト"
      ],
      "metadata": {
        "id": "mBf4mW6mVzww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習、テストで用いていない画像データで試す\n",
        "for index, classlabel in enumerate(classes):\n",
        "  # 描画用意\n",
        "  plt.figure(figsize=(16, 5))\n",
        "\n",
        "  # フォルダにある特定の種類の動物の画像ファイルを読み込む\n",
        "  photos_dir = \"./\" + classlabel\n",
        "  files = glob.glob(photos_dir + \"/*.jpg\")\n",
        "  for i, file in enumerate(files[140:145]):\n",
        "    # 画像データを１つずつ読み込み、サイズ等調整\n",
        "    image = Image.open(file)\n",
        "    image = image.convert(\"RGB\")\n",
        "    image = image.resize((image_size, image_size))\n",
        "    data = np.asarray(image)\n",
        "    X_check = np.asarray(data)\n",
        "    X_check = torch.from_numpy(X_check.astype(np.float32) * 2 / 255 - 1)\n",
        "\n",
        "    # 画像データの描画\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(X_check * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    plt.title(classlabel)\n",
        "\n",
        "    # 予測\n",
        "    X_check = torch.reshape(X_check, (-1, 3, image_size, image_size))\n",
        "    X_check = X_check.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X_check)\n",
        "    pred = softmax(pred)\n",
        "    print(classlabel + str(i) + f\"の予測結果: 犬={pred[0, 0]*100:.3f}%, 猫={pred[0, 1]*100:.3f}% -> 結果: {classes[torch.argmax(pred[0])]}\")\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "vWKn7cQjV1tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの重みの保存・読み込み"
      ],
      "metadata": {
        "id": "kkeZ4AYfWJGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "pYHqDqYPWMsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model.pth', map_location=device))"
      ],
      "metadata": {
        "id": "LxVpaEvaWOEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}